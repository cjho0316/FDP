[2024-02-27 15:04:12,455] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: elt_reddit_pipeline.upload_to_s3 manual__2024-02-27T15:04:06.334861+00:00 [queued]>
[2024-02-27 15:04:12,459] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: elt_reddit_pipeline.upload_to_s3 manual__2024-02-27T15:04:06.334861+00:00 [queued]>
[2024-02-27 15:04:12,459] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2024-02-27 15:04:12,459] {taskinstance.py:1357} INFO - Starting attempt 1 of 2
[2024-02-27 15:04:12,460] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2024-02-27 15:04:12,467] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): upload_to_s3> on 2024-02-27 15:04:06.334861+00:00
[2024-02-27 15:04:12,470] {standard_task_runner.py:52} INFO - Started process 3216 to run task
[2024-02-27 15:04:12,473] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'elt_reddit_pipeline', 'upload_to_s3', 'manual__2024-02-27T15:04:06.334861+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/elt_reddit_pipeline.py', '--cfg-path', '/tmp/tmp_cd5l5vr', '--error-file', '/tmp/tmp4tqjvxpw']
[2024-02-27 15:04:12,473] {standard_task_runner.py:80} INFO - Job 11: Subtask upload_to_s3
[2024-02-27 15:04:12,508] {task_command.py:370} INFO - Running <TaskInstance: elt_reddit_pipeline.upload_to_s3 manual__2024-02-27T15:04:06.334861+00:00 [running]> on host cd52d40776f5
[2024-02-27 15:04:12,557] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=elt_reddit_pipeline
AIRFLOW_CTX_TASK_ID=upload_to_s3
AIRFLOW_CTX_EXECUTION_DATE=2024-02-27T15:04:06.334861+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-02-27T15:04:06.334861+00:00
[2024-02-27 15:04:12,558] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2024-02-27 15:04:12,559] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'python /opt/***/extraction/upload_aws_s3_etl.py 20240227']
[2024-02-27 15:04:12,568] {subprocess.py:85} INFO - Output:
[2024-02-27 15:04:13,171] {subprocess.py:92} INFO - Traceback (most recent call last):
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -   File "/opt/***/extraction/upload_aws_s3_etl.py", line 73, in <module>
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -     main()
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -   File "/opt/***/extraction/upload_aws_s3_etl.py", line 35, in main
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -     create_bucket_if_not_exists(conn)
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -   File "/opt/***/extraction/upload_aws_s3_etl.py", line 53, in create_bucket_if_not_exists
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -     conn.meta.client.head_bucket(Bucket=BUCKET_NAME)
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/client.py", line 508, in _api_call
[2024-02-27 15:04:13,172] {subprocess.py:92} INFO -     return self._make_api_call(operation_name, kwargs)
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/client.py", line 875, in _make_api_call
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -     api_params, operation_model, context=request_context
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/client.py", line 933, in _convert_to_request_dict
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -     api_params, operation_model, context
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/client.py", line 969, in _emit_api_params
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -     context=context,
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/hooks.py", line 412, in emit
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -     return self._emitter.emit(aliased_event_name, **kwargs)
[2024-02-27 15:04:13,173] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/hooks.py", line 256, in emit
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO -     return self._emit(event_name, kwargs)
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/hooks.py", line 239, in _emit
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO -     response = handler(**kwargs)
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO -   File "/home/***/.local/lib/python3.7/site-packages/botocore/handlers.py", line 276, in validate_bucket_name
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO -     raise ParamValidationError(report=error_msg)
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO - botocore.exceptions.ParamValidationError: Parameter validation failed:
[2024-02-27 15:04:13,174] {subprocess.py:92} INFO - Invalid bucket name ""janghodashboardbucket"": Bucket name must match the regex "^[a-zA-Z0-9.\-_]{1,255}$" or be an ARN matching the regex "^arn:(aws).*:(s3|s3-object-lambda):[a-z\-0-9]*:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\-.]{1,63}$|^arn:(aws).*:s3-outposts:[a-z\-0-9]+:[0-9]{12}:outpost[/:][a-zA-Z0-9\-]{1,63}[/:]accesspoint[/:][a-zA-Z0-9\-]{1,63}$"
[2024-02-27 15:04:13,199] {subprocess.py:96} INFO - Command exited with return code 1
[2024-02-27 15:04:13,213] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 195, in execute
    f'Bash command failed. The command returned a non-zero exit code {result.exit_code}.'
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-02-27 15:04:13,217] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=elt_reddit_pipeline, task_id=upload_to_s3, execution_date=20240227T150406, start_date=20240227T150412, end_date=20240227T150413
[2024-02-27 15:04:13,229] {standard_task_runner.py:97} ERROR - Failed to execute job 11 for task upload_to_s3 (Bash command failed. The command returned a non-zero exit code 1.; 3216)
[2024-02-27 15:04:13,255] {local_task_job.py:156} INFO - Task exited with return code 1
[2024-02-27 15:04:13,284] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
